

<!DOCTYPE html>
<html class="writer-html5" lang="english" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Softmax &mdash; MiniTorch 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/jupyter-sphinx.css" type="text/css" />
  <link rel="stylesheet" href="_static/thebelab.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/thebelab-helper.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Pooling" href="pooling.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> MiniTorch
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="setup.html">Workspace Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="mlprimer.html">ML Primer</a></li>
<li class="toctree-l1"><a class="reference internal" href="module0.html">Module 0 - Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="module1.html">Module 1 - Auto-Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="module2.html">Module 2 - Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="module3.html">Module 3 - Efficiency</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="module4.html">Module 4 - Networks</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="convolution.html">Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="pooling.html">Pooling</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Softmax</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sigmoid">Sigmoid</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multiclass">Multiclass</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="module4.html#tasks">Tasks</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MiniTorch</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="module4.html">Module 4 - Networks</a> &raquo;</li>
        
      <li>Softmax</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/softmax.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="softmax">
<h1>Softmax<a class="headerlink" href="#softmax" title="Permalink to this headline">¶</a></h1>
<div class="section" id="sigmoid">
<h2>Sigmoid<a class="headerlink" href="#sigmoid" title="Permalink to this headline">¶</a></h2>
<p>So far, the key function that we have relied on for calculating loss
is the <a class="reference external" href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid</a>
function.  As visualized below, it goes to zero for large negative
inputs, and goes to 1 for large positive inputs. In between, it forms
a smooth S-curve.</p>
<a class="reference internal image-reference" href="_images/sigmoid.png"><img alt="_images/sigmoid.png" class="align-center" src="_images/sigmoid.png" style="width: 400px;" /></a>
<p>As we saw in Module 1, sigmoid function makes it easier to aply
auto-differentiation when training our models. It can be thought of as
a smooth version of the step function <span class="math notranslate nohighlight">\(x &gt; 0\)</span>, which signals
whether <span class="math notranslate nohighlight">\(x\)</span> is greater than zero by returning a binary value.
Another way to write this step function is <span class="math notranslate nohighlight">\(step(x) = argmax\{0,
x\}\)</span>, i.e. returns which argument is bigger, 0 or 1. Whereas step
function returns a binary choice, sigmoid function gives a &quot;softer&quot;
differentiable choice.</p>
<p>We can connect sigmoid function to another function that we have used
in previous MiniTorch Modules: the ReLU function that we use for
activations. Recall that this function is defined as <span class="math notranslate nohighlight">\(ReLU(x) =
max\{ 0, x\}\)</span> with the following derivative function:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\text{ReLU'}(x) = \begin{cases} 0 &amp; \text{if } x \leq 0 \\ 1 &amp; \text{ow}  \end{cases}\end{split}\]</div>
<a class="reference internal image-reference" href="_images/relu2.png"><img alt="_images/relu2.png" class="align-center" src="_images/relu2.png" style="width: 400px;" /></a>
<p>As a summary, we can connect the above three functions:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 26%" />
<col style="width: 74%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Function</p></th>
<th class="head"><p>Comparison (x with 0)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ReLU</p></td>
<td><p>Max</p></td>
</tr>
<tr class="row-odd"><td><p>Step</p></td>
<td><p>Arg Max</p></td>
</tr>
<tr class="row-even"><td><p>Sigmoid</p></td>
<td><p>&quot;Soft&quot; Max</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="multiclass">
<h2>Multiclass<a class="headerlink" href="#multiclass" title="Permalink to this headline">¶</a></h2>
<p>The sigmoid function works great for binary classification problems.
However, for many problems, we may want to do <cite>multiclass</cite>
classification, where we have <span class="math notranslate nohighlight">\(K\)</span> possible output classes to
select from. For these problems, we can assume that the model should
output a <span class="math notranslate nohighlight">\(K\)</span>-dimensional vector which gives a score for each of
the K possible classes:</p>
<img alt="_images/value.png" src="_images/value.png" />
<p>Naturally, we pick the output class that has the highest score. Given a vector,
argmax function returns a one-hot vector with 1 at the position of the
highest-scored element and 0 for all other elements:</p>
<img alt="_images/argmax.png" src="_images/argmax.png" />
<p>While argmax function seems a bit different at the first glance, we
can view it as a generalization of the <span class="math notranslate nohighlight">\(x &gt; 0\)</span> function: each
position is either 0 or 1.  We can also see that its derivative will
be zero almost everywhere: a small perturbation to the input will not
change the output value.</p>
<p>In order to fix this issue, we need a soft version of the argmax
function, just like sigmoid function smooths over the input
changes. The generalization of sigmoid function is appropriately known
as the <cite>softmax</cite> function, which is computed as:</p>
<div class="math notranslate nohighlight">
\[\text{softmax}(\textbf{x}) = \frac{\exp \textbf{x}}{\sum_i \exp x_i}\]</div>
<img alt="_images/softmax.png" src="_images/softmax.png" />
<p>Like the sigmoid function, every value of softmax function is between
0 and 1, and a small change to any of the input scores will result in
a change to all of the output values.</p>
<p>As the softmax function requires exponentiating the input scores, it can be
numerically unstable in practice. Therefore it is common to use a
numerical trick to compute the log of the softmax function instead:</p>
<div class="math notranslate nohighlight">
\[\text{logsoftmax}(\textbf{x}) = \textbf{x} - \log \sum_i \exp x_i
                              = \textbf{x} - \log(\sum_i \exp (x_i - m)) - m\]</div>
<p>where <span class="math notranslate nohighlight">\(m\)</span> is the max element of <span class="math notranslate nohighlight">\(\textbf{x}\)</span>. This trick
is common enough that there is a nice derivation on <a class="reference external" href="https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations">wikipedia</a>.
(This is a pratical trick for sigmoid function as well, which we
ignored in earlier modules.)</p>
<p>Speaking of max, we can add a max operator to our code base.  We can
compute the max of a vector (or tensor in general) as a reduction,
which returns the single highest-scored element in the
input. Intuitively, we can think about how small changes to the input
impact this returned value. Ignoring ties, only the element that has
the highest score will have a non-zero derivative, and its derivative
will be 1.  Thereforce the gradient of the max reduction is a one-hot
vector with 1 for the highest-scored element, i.e. the argmax
function.</p>
<p>Here is a summary of how functions for binary classficiaiton connect
with functions for multiclass classification:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 37%" />
<col style="width: 63%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Binary</p></th>
<th class="head"><p>Multiclass</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ReLU</p></td>
<td><p>Max</p></td>
</tr>
<tr class="row-odd"><td><p>Step</p></td>
<td><p>Argmax</p></td>
</tr>
<tr class="row-even"><td><p>Sigmoid</p></td>
<td><p>Softmax</p></td>
</tr>
</tbody>
</table>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="pooling.html" class="btn btn-neutral float-left" title="Pooling" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, Sasha Rush.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>